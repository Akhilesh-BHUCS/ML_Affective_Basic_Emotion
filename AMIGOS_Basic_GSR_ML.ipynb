{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhilesh-BHUCS/ML_Affective_Basic_Emotion/blob/main/AMIGOS_Basic_GSR_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMcUTisy_8iG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqsE7aWamE2f"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC_1idqeeOxS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmvHofGme04O"
      },
      "outputs": [],
      "source": [
        "data= pd.read_csv('/content/drive/MyDrive/AMIGOS/AMIGO_GSR_Discrete_Emotion_Combined.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6doFv7e_vu6J"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eehDCtsAv-6w"
      },
      "outputs": [],
      "source": [
        "data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRQzw2pkxlBM"
      },
      "outputs": [],
      "source": [
        "data['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg3ZNCKUxwiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label = LabelEncoder()\n",
        "data['label'] = label.fit_transform(data['Label'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N87DxanG6Inq"
      },
      "outputs": [],
      "source": [
        "df = data.drop(['Label'], axis = 1).copy()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVuMY8wIoKJb"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn6Rsb3d6hoO"
      },
      "outputs": [],
      "source": [
        "df1 = df.astype('float').copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azaXFW1inREB"
      },
      "outputs": [],
      "source": [
        "#library addition\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_validate, cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haXwlfHgnXFw"
      },
      "outputs": [],
      "source": [
        "#determine the number of classes(labels)\n",
        "label_encoder = LabelEncoder().fit(df.label)\n",
        "labels = label_encoder.transform(df.label)\n",
        "classes = list(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erO2FR1J4bU1"
      },
      "outputs": [],
      "source": [
        "#split train data into validation and train\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLEDZU588c6v"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkqpNhsmCJX-"
      },
      "outputs": [],
      "source": [
        "#split train data into validation and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU8fW0F2CO0i"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBFeBmUaCO6e"
      },
      "outputs": [],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit"
      ],
      "metadata": {
        "id": "Kr6rlCA1_HKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "\n",
        "    if axes is None:\n",
        "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    axes[0].set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes[0].set_ylim(*ylim)\n",
        "    axes[0].set_xlabel(\"Training examples\")\n",
        "    axes[0].set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes[0].grid()\n",
        "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "\n",
        "    # Plot n_samples vs fit_times\n",
        "    axes[1].grid()\n",
        "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
        "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
        "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
        "    axes[1].set_xlabel(\"Training examples\")\n",
        "    axes[1].set_ylabel(\"fit_times\")\n",
        "    axes[1].set_title(\"Scalability of the model\")\n",
        "\n",
        "    # Plot fit_time vs score\n",
        "    axes[2].grid()\n",
        "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
        "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
        "    axes[2].set_xlabel(\"fit_times\")\n",
        "    axes[2].set_ylabel(\"Score\")\n",
        "    axes[2].set_title(\"Performance of the model\")\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "nHBV8rI2_INy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd-pNh_RCVgF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn import linear_model\n",
        "# Python script for confusion matrix creation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMgQI7F0CXFo"
      },
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    linear_model.LogisticRegression(penalty='l2', tol=0.0001, C=1.0, max_iter=100),\n",
        "    KNeighborsClassifier(n_neighbors=5, algorithm='auto', leaf_size=30),\n",
        "    RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_leaf_nodes=None),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9OjysXtCZMe"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2ev9IBbCcqw"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import ShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB55rA9ypbCu"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJBjWYdjCfL_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "for clf in classifiers:\n",
        "    print(clf)\n",
        "    start_time = time.time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    name = clf.__class__.__name__\n",
        "    print(\"=\"*30)\n",
        "    print(name)\n",
        "\n",
        "    print('****Results****')\n",
        "    train_predictions = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test,train_predictions)\n",
        "    print(\"Accuracy: {:.4%}\".format(acc))\n",
        "    train_predictions = clf.predict_proba(X_test)\n",
        "    ll = log_loss(y_test, train_predictions)\n",
        "    print(\"Log Loss: {}\".format(ll))\n",
        "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(confusion_matrix(y_test,y_pred))\n",
        "    print(accuracy_score(y_test,y_pred))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    plot_confusion_matrix(conf_mat=confusion_matrix(y_test,y_pred),colorbar=True,show_absolute=False, show_normed=True, figsize=(7,7))\n",
        "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "    print(\"10-fold validation test\")\n",
        "    print (np.mean(cross_val_score(clf, X_train, y_train, cv=10)))\n",
        "    print(\"Get performance metrics\")\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    precision = precision_score(y_test,y_pred, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    recall = recall_score(y_test,y_pred, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    f1 = f1_score(y_test,y_pred, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    kappa = cohen_kappa_score(y_test,y_pred)\n",
        "    print('Cohens kappa: %f' % kappa)\n",
        "\n",
        "\n",
        "    matrix = confusion_matrix(y_test,y_pred)\n",
        "    print(matrix)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
        "\n",
        "    title = clf\n",
        "    cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
        "\n",
        "    estimator = clf\n",
        "    plot_learning_curve(estimator, title, X_train, y_train, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
        "                    cv=cv, n_jobs=4)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"complete !!!\")\n",
        "\n",
        "print(\"=\"*30)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ddkEb0c8LZWCFMX03zjt15Mabn6JDCR-",
      "authorship_tag": "ABX9TyN8Uan7SXMuVI3AQe+NUTas",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}